{
 "cells": [
  {
   "cell_type": "code",
   "id": "9ddf7cba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T02:02:06.968627Z",
     "start_time": "2025-07-24T02:02:00.298299Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from keras.src.applications.resnet import ResNet50\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    'C:/Users/Natalia/Desktop/PADIA/endansys/dataset/training',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    'C:/Users/Natalia/Desktop/PADIA/endansys/dataset/validation',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    'C:/Users/Natalia/Desktop/PADIA/endansys/dataset/testing',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.1),\n",
    "    layers.RandomTranslation(0.1, 0.1),\n",
    "])\n",
    "\n",
    "base_model = ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Resizing(224, 224),\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(train_ds.class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=35,\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "val_loss, val_acc = model.evaluate(val_ds)\n",
    "print(f\"Precisión en validación: {val_acc:.2%}\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Precisión en test: {test_acc:.2%}\")\n",
    "\n",
    "#Aqui empieza el fine-tuning\n",
    "base_model.trainable = True\n",
    "fine_tune = 140\n",
    "\n",
    "for layer in base_model.layers[:fine_tune]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Recompilar con un learning mas bajo para el fine-tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.000001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Entrenamiento fine-tuning\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=25,\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "val_loss, val_acc = model.evaluate(val_ds)\n",
    "print(f\"Precisión en validación con fine-tuning: {val_acc:.2%}\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Precisión en test con fine-tuning: {test_acc:.2%}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1429 files belonging to 56 classes.\n",
      "Found 283 files belonging to 56 classes.\n",
      "Found 367 files belonging to 56 classes.\n",
      "Epoch 1/35\n",
      "WARNING:tensorflow:From C:\\Users\\Natalia\\Desktop\\PADIA\\animales\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node decode_image/DecodeImage defined at (most recent call last):\n<stack traces unavailable>\nUnknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]]\n\t [[IteratorGetNext]] [Op:__inference_multi_step_on_iterator_12762]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 68\u001B[0m\n\u001B[0;32m     59\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     60\u001B[0m               loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     61\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     63\u001B[0m early_stopping \u001B[38;5;241m=\u001B[39m EarlyStopping(\n\u001B[0;32m     64\u001B[0m     patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[0;32m     65\u001B[0m     restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 68\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m          \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m35\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m          \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     73\u001B[0m val_loss, val_acc \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(val_ds)\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrecisión en validación: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2%\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\PADIA\\animales\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\Desktop\\PADIA\\animales\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     54\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node decode_image/DecodeImage defined at (most recent call last):\n<stack traces unavailable>\nUnknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]]\n\t [[IteratorGetNext]] [Op:__inference_multi_step_on_iterator_12762]"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9e194acf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T21:34:03.665793Z",
     "start_time": "2025-07-23T21:34:03.642771Z"
    }
   },
   "source": [
    "class_names = train_ds.class_names"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "ea71efe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T21:34:03.855548Z",
     "start_time": "2025-07-23T21:34:03.848043Z"
    }
   },
   "source": [
    "#print(\"Predicted index:\", predicted_class)\n",
    "print(\"Class names:\", class_names)\n",
    "print(\"Number of classes:\", len(class_names))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['Aguila_arpia', 'Anaconda', 'Armadillo_gigante', 'Boa_constrictor', 'Buho_cornudo', 'Cacique_candela', 'Caiman_aguja', 'Capibara', 'Caracara', 'Colibri_esmeralda', 'Condor_de_los_Andes', 'Cusumbo', 'Delfin_rosado', 'Flamenco', 'Gallito_de_roca', 'Garza_blanca', 'Guacamaya_azulamarilla', 'Guacamaya_roja', 'Guatin', 'Hormiguero_gigante', 'Iguana_verde', 'Jaguar', 'Jaguarundi', 'Lagarto_azul', 'Loro_orejiamarillo', 'Manati_del_Caribe', 'Marimonda', 'Martin_pescador', 'Mico_titi_gris', 'Mono_aullador', 'Mono_lanudo', 'Mono_nocturno', 'Musarana_de_cola_corta_colombiana', 'Neque', 'Nutria_gigante', 'Oso_andino', 'Oso_de_anteojos', 'Paujil', 'Pecari_de_collar', 'Perezoso_de_dos_dedos', 'Perico_carisucio', 'Perro_de_monte', 'Puma', 'Rana_de_cristal', 'Rana_dorada', 'Rana_venenosa_azul', 'Tapaculo', 'Tapir_amazonico', 'Tigrillo', 'Tinamu', 'Titi_cabeciblanco', 'Tortuga_charapa', 'Tucan_toco', 'Venado_cola_blanca', 'Zorrillo_listado', 'Zorro_cangrejero']\n",
      "Number of classes: 56\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "b8856283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T21:34:03.965691Z",
     "start_time": "2025-07-23T21:34:03.941665Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "# Crear diccionario con los índices de clase\n",
    "class_names = train_ds.class_names\n",
    "class_indices = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "# Guardar en JSON\n",
    "with open(\"class_indices.json\", \"w\") as f:\n",
    "    json.dump(class_indices, f)\n",
    "\n",
    "print(\"class_indices.json\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_indices.json\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "428bfbd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T21:34:04.407171Z",
     "start_time": "2025-07-23T21:34:04.014252Z"
    }
   },
   "source": [
    "model.save(\"animal_species_classifier.h5\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "610289ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T21:34:05.044238Z",
     "start_time": "2025-07-23T21:34:04.424685Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"animal_species_classifier.h5\",\n",
    "                                   custom_objects={'preprocess_input': preprocess_input})"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "405e026a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T21:36:01.807131Z",
     "start_time": "2025-07-23T21:36:01.716982Z"
    }
   },
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "img_path = \"C:/Users/Natalia/Desktop/PADIA/endansys/dataset/testing/Venado_cola_blanca/5.jpg\"  # Cambia esto por la ruta de tu imagen\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Cargar imagen y redimensionar\n",
    "img = load_img(img_path, target_size=img_size)\n",
    "\n",
    "# Convertir a array y escalar\n",
    "img_array = img_to_array(img)\n",
    "img_array = preprocess_input(img_array)  # Normalizar igual que en el modelo\n",
    "\n",
    "# Expandir dimensiones para simular un batch de tamaño 1\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "confidence = 100 * np.max(predictions[0])\n",
    "\n",
    "print(f\"La imagen probablemente pertenece a '{class_names[predicted_class]}' con una confianza de {confidence:.2f}%\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "La imagen probablemente pertenece a 'Venado_cola_blanca' con una confianza de 94.66%\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19472bccebdeb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T21:34:05.245586400Z",
     "start_time": "2025-05-21T04:09:52.462573Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
